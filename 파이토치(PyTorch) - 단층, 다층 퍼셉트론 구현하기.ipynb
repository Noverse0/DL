{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단층, 다층 퍼셉트론 구현하기\n",
    "\n",
    "단층 퍼셉트론으로 XOR 문제가 풀이가 가능할지 구현한다.\n",
    "\n",
    "또한, 다층 퍼셉트론으로 XOR 문제가 풀이가 가능할지 구현한다.\n",
    "\n",
    "퍼셉트론 개념: https://www.notion.so/noversezero/Perceptron-5e5516a2c5ee42d59f2f8f854dcc898d\n",
    "\n",
    "퍼셉트론 XOR 문제: https://www.notion.so/noversezero/XOR-a68e503051f740c6b7649e40fdc13dd0\n",
    "\n",
    "다층 퍼셉트론 개념: https://www.notion.so/noversezero/MLP-d57ac1a6d3024fa2a36675b4dd65e609"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU로 할것인지 GPU로 할 것인지 확인하는 구문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XOR 문제를 확인하기 위해 tensor를 만든다.\n",
    "\n",
    "  X   =  Y\n",
    "  \n",
    "[0,0] = [0]\n",
    "\n",
    "[0,1] = [1]\n",
    "\n",
    "[1,0] = [1]\n",
    "\n",
    "[1,1] = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단층 퍼셉트론으로 XOR 문제 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(2, 1, bias=True) #input 2개 output 1개의 Linear model\n",
    "sigmoid = nn.Sigmoid()\n",
    "model = nn.Sequential(linear, sigmoid) #model의 Active Function은 Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = torch.nn.BCELoss() # Binary Cross Entropy로 정의\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1) # learning rate = 1,확률적 경사하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931471824645996\n",
      "1000 0.6931471824645996\n",
      "2000 0.6931471824645996\n",
      "3000 0.6931471824645996\n",
      "4000 0.6931471824645996\n",
      "5000 0.6931471824645996\n",
      "6000 0.6931471824645996\n",
      "7000 0.6931471824645996\n",
      "8000 0.6931471824645996\n",
      "9000 0.6931471824645996\n",
      "10000 0.6931471824645996\n"
     ]
    }
   ],
   "source": [
    "#10,001번의 에포크 수행. 0번 에포크부터 10,000번 에포크까지.\n",
    "for step in range(10001): \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0: # 1000번째 에포크마다 비용 출력\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  0.5\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다층 퍼셉트론으로 XOR 문제 풀기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단층 퍼셉트론과 같지만 model을 만들때 Sequential을 다층으로 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
    "          nn.Sigmoid()\n",
    "          ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.695870041847229\n",
      "1000 0.6931446194648743\n",
      "2000 0.6931255459785461\n",
      "3000 0.6930868029594421\n",
      "4000 0.6929389834403992\n",
      "5000 0.6887685060501099\n",
      "6000 0.001516415155492723\n",
      "7000 0.0005303305806592107\n",
      "8000 0.0003135718870908022\n",
      "9000 0.0002205626224167645\n",
      "10000 0.0001693219819571823\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    # forward 연산\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 1000의 배수에 해당되는 에포크마다 비용을 출력\n",
    "    if epoch % 1000 == 0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[1.2716786e-04]\n",
      " [9.9983418e-01]\n",
      " [9.9984252e-01]\n",
      " [2.2669900e-04]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
