{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression\n",
    "\n",
    "Softmax에 대한 자세한 설명은 제 Notion 페이지에 있습니다.\n",
    "\n",
    "https://noversezero.notion.site/Softmax-Regression-443d6bf93b234f11a3e6134130953d7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist 데이터 로딩 \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " mnist 데이터는 6만개의 train 데이터와 1만개의 test 데이터로 이루어져있습니다.\n",
    " \n",
    " 한개의 데이터는 28, 28의 2차원 배열 형태로 저장이 되어 있습니다.\n",
    " \n",
    " 즉, 가로 28, 세로 28의 흑백 이미지들의 집합입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covert uint8 to float32\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten images to 1-0 vector of 784 features (28*28), 1차원 벡터로 변환\n",
    "x_train, x_test = x_train.reshape([-1, 28*28]), x_test.reshape([-1, 28*28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reshape(-1, x)는 2차원이던 shape를 1차원으로 줄이라는 뜻이다.\n",
    "\n",
    "즉, x_train.reshape([-1, 28x28])은 x_train의 모든 원소들을 28x28(왜냐 한 데이터가 28x28 차원이기 때문에)의 1차원 벡터로 바꾼다는 의미이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize images value from [0, 255] to [0,1] \n",
    "#0부터 255까지 숫자로 되어 있는 것을 255로 나누어서 Nomalization\n",
    "x_train, x_test = x_train / 255, x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 데이터를 이해하기 휩게 0과 1사이의 실수값으로 데이터를 변환하는게 필요합니다.\n",
    "\n",
    "255로 나누어 0과 1사이의 값으로 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot-Encoding\n",
    "one_hot_y_train = np.eye(10)[y_train]\n",
    "one_hot_y_test = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_train과 y_test를 One Hot Encoding으로 만드는 것이다.\n",
    "\n",
    "np.eye(n)은 nxn의 단위행렬을 만드는 것이다.\n",
    "\n",
    "원래 np.eye(n)은 대각행렬에 1이 위치하지만, 뒤에 [y_test or train]을 통해 1이 위치하는 위치를 조정할 수 있다.\n",
    "\n",
    "즉, 한 행에 1이 1개이고 나머지가 0인 One-Hot-Encoding이 된 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size을 정의하고, 학습\n",
    "batch_size = 512\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, one_hot_y_train))\n",
    "#5000번 섞고, batch size만큼 뽑아서 학습\n",
    "train_data = train_data.shuffle(5000).batch(batch_size).prefetch(1)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((x_test, one_hot_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.data.Dataset.from_tensor_slices()은 Dataset을 생성하는 함수이다.\n",
    "\n",
    "우리는 로컬 파일이나 메모리에 올려져 있는 데이터를 모델로 집어 넣어 평가하고 연산하고 다양한 작업을 진행하게 된다.\n",
    "\n",
    "이때 우리의 데이터가 일정 순서에 따라서 작업이 진행될 수 있도록 도와주는 것이다.\n",
    "\n",
    "따라서 이를 파이프 라인 빌드라고 한다.\n",
    "\n",
    "prefetch(1)은 Dataset이 항상 한 Batch가 미리 준비되어 있도록 준비해준다.\n",
    "\n",
    "즉, 어떤 Batch가 모델에 들어가서 연산을 진행하고 있을때, 연산이 끝나면 바로 다른 하나의 Batch를 넣을 수 있도록 준비를 해놓는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 정의\n",
    "model = tf.keras.models.Sequential()\n",
    "# Softmax를 이용하고 출력이 10개 0~9 중 한개의 값으로 예측\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD 방법으로 Optimizer를 사용하고, Cross-Entropy를 사용하여 Loss Function을 계산한다.\n",
    "model.compile(optimizer='sgd', loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.8535 - accuracy: 0.4797\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.2873 - accuracy: 0.7439\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 1.0262 - accuracy: 0.7964\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.8825 - accuracy: 0.8189\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.7917 - accuracy: 0.8314\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.7287 - accuracy: 0.8394\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6822 - accuracy: 0.8455\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.6462 - accuracy: 0.8504\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.6175 - accuracy: 0.8541\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5939 - accuracy: 0.8573\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5741 - accuracy: 0.8600\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5572 - accuracy: 0.8623\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.5426 - accuracy: 0.8645\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.8668\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.5185 - accuracy: 0.8686\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.5083 - accuracy: 0.8704\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4992 - accuracy: 0.8723\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4910 - accuracy: 0.8740\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4835 - accuracy: 0.8752\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4766 - accuracy: 0.8767\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.8776\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.8786\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.8796\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4540 - accuracy: 0.8806\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4493 - accuracy: 0.8814\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4449 - accuracy: 0.8819\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.4407 - accuracy: 0.8827\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.4368 - accuracy: 0.8838\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4331 - accuracy: 0.8846\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4296 - accuracy: 0.8851\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4263 - accuracy: 0.8860\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4232 - accuracy: 0.8867\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8873\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4173 - accuracy: 0.8880\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4146 - accuracy: 0.8884\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.4120 - accuracy: 0.8891\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4095 - accuracy: 0.8895\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4072 - accuracy: 0.8901\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.4049 - accuracy: 0.8905\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4027 - accuracy: 0.8910\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.8915\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.3985 - accuracy: 0.8917\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.3966 - accuracy: 0.8922\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.3947 - accuracy: 0.8927\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3929 - accuracy: 0.8932\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3911 - accuracy: 0.8937\n",
      "Epoch 47/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3894 - accuracy: 0.8939\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.3878 - accuracy: 0.8943\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.3862 - accuracy: 0.8949\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.3846 - accuracy: 0.8953\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3831 - accuracy: 0.8955\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3817 - accuracy: 0.8959\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.3803 - accuracy: 0.8965\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3789 - accuracy: 0.8966\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3776 - accuracy: 0.8970\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3763 - accuracy: 0.8973\n",
      "Epoch 57/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3750 - accuracy: 0.8976\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3738 - accuracy: 0.8979\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3726 - accuracy: 0.8981\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3714 - accuracy: 0.8984\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.3703 - accuracy: 0.8988\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3692 - accuracy: 0.8989\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3681 - accuracy: 0.8991\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.8994\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3660 - accuracy: 0.8996\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3650 - accuracy: 0.8996\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3640 - accuracy: 0.8998\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3631 - accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3622 - accuracy: 0.9002\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3612 - accuracy: 0.9005\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3603 - accuracy: 0.9007\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3594 - accuracy: 0.9008\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3586 - accuracy: 0.9011\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.3577 - accuracy: 0.9014\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3569 - accuracy: 0.9016\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.9016\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3553 - accuracy: 0.9018\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3545 - accuracy: 0.9021\n",
      "Epoch 79/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3538 - accuracy: 0.9023\n",
      "Epoch 80/100\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.3530 - accuracy: 0.9025\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3523 - accuracy: 0.9027\n",
      "Epoch 82/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3516 - accuracy: 0.9028\n",
      "Epoch 83/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3509 - accuracy: 0.9032\n",
      "Epoch 84/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3502 - accuracy: 0.9033\n",
      "Epoch 85/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3495 - accuracy: 0.9035\n",
      "Epoch 86/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3488 - accuracy: 0.9036\n",
      "Epoch 87/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3481 - accuracy: 0.9038\n",
      "Epoch 88/100\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.3475 - accuracy: 0.9040\n",
      "Epoch 89/100\n",
      "118/118 [==============================] - 1s 6ms/step - loss: 0.3468 - accuracy: 0.9041\n",
      "Epoch 90/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3462 - accuracy: 0.9042\n",
      "Epoch 91/100\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.3456 - accuracy: 0.9044\n",
      "Epoch 92/100\n",
      "118/118 [==============================] - 1s 9ms/step - loss: 0.3450 - accuracy: 0.9047\n",
      "Epoch 93/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3444 - accuracy: 0.9048\n",
      "Epoch 94/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.9048\n",
      "Epoch 95/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3432 - accuracy: 0.9051\n",
      "Epoch 96/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3427 - accuracy: 0.9052\n",
      "Epoch 97/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3421 - accuracy: 0.9053\n",
      "Epoch 98/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3415 - accuracy: 0.9055\n",
      "Epoch 99/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3410 - accuracy: 0.9056\n",
      "Epoch 100/100\n",
      "118/118 [==============================] - 1s 5ms/step - loss: 0.3405 - accuracy: 0.9056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21ebfb65490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.9113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32487383484840393, 0.911300003528595]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, one_hot_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted :  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4579\n",
    "# 4579번째 그림을 출력\n",
    "plt.imshow(x_test[i].reshape(28, 28))\n",
    "print(\"predicted : \", np.argmax(model.predict(np.array([x_test[i]])), axis=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted :  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 12\n",
    "# 4579번째 그림을 출력\n",
    "plt.imshow(x_test[i].reshape(28, 28))\n",
    "print(\"predicted : \", np.argmax(model.predict(np.array([x_test[i]])), axis=1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.06954933e-04, 2.31264465e-04, 1.04430810e-01, 3.83971055e-04,\n",
       "        4.91999043e-03, 6.95372978e-03, 8.57234657e-01, 6.11936912e-06,\n",
       "        2.56160628e-02, 1.16364514e-04]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([x_test[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지정한 영역에서 argmax는 최대값을 찾아주는 함수이다.\n",
    "\n",
    "np.array([x_test[4579]])에서 가장 큰 수를 찾아서 해당 위치의 값을 print하는 것이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
